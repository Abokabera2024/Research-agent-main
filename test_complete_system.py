"""
Comprehensive end-to-end test of the research agent.
Tests the complete pipeline without requiring OpenAI API key.
"""
import sys
import os
import json
from pathlib import Path

# Add src to path
sys.path.append('/home/runner/work/Research-agent/Research-agent/src')

# Mock the OpenAI components to test without API key
class MockOpenAIEmbeddings:
    def __init__(self, model=None):
        self.model = model
    
    def embed_documents(self, texts):
        # Return simple mock embeddings
        return [[0.1] * 100 for _ in texts]
    
    def embed_query(self, text):
        return [0.1] * 100

class MockChatOpenAI:
    def __init__(self, model=None, temperature=0):
        self.model = model
        self.temperature = temperature
    
    def invoke(self, messages):
        # Return mock response based on content
        content = str(messages)
        
        if "analyze" in content.lower():
            return MockResponse(json.dumps({
                "findings": ["Mock finding 1", "Mock finding 2"],
                "stats": {"mock_stat": 123},
                "needs_scipy": True,
                "rationale": "Mock analysis rationale"
            }))
        elif "decide" in content.lower():
            return MockResponse(json.dumps({
                "label": "relevant",
                "confidence": 0.85,
                "criteria": ["Mock criterion 1", "Mock criterion 2"]
            }))
        else:
            return MockResponse("Mock response")

class MockResponse:
    def __init__(self, content):
        self.content = content

class MockChroma:
    def __init__(self, **kwargs):
        self.docs = []
    
    @classmethod
    def from_texts(cls, texts, embedding, metadatas, persist_directory):
        instance = cls()
        instance.docs = [MockDoc(text, meta) for text, meta in zip(texts, metadatas)]
        return instance
    
    def as_retriever(self, search_kwargs=None):
        return MockRetriever(self.docs)
    
    def similarity_search(self, query, k=5):
        return self.docs[:k]

class MockRetriever:
    def __init__(self, docs):
        self.docs = docs
    
    def get_relevant_documents(self, query):
        return self.docs[:5]  # Return first 5 docs

class MockDoc:
    def __init__(self, text, metadata):
        self.page_content = text
        self.metadata = metadata

# Patch the modules
import sys
import importlib

# Mock langchain_openai
mock_langchain_openai = type('MockModule', (), {
    'OpenAIEmbeddings': MockOpenAIEmbeddings,
    'ChatOpenAI': MockChatOpenAI
})
sys.modules['langchain_openai'] = mock_langchain_openai

# Mock langchain_community.vectorstores
mock_vectorstores = type('MockModule', (), {
    'Chroma': MockChroma
})
mock_community = type('MockModule', (), {
    'vectorstores': mock_vectorstores
})
sys.modules['langchain_community'] = mock_community
sys.modules['langchain_community.vectorstores'] = mock_vectorstores

def test_complete_pipeline():
    """Test the complete research agent pipeline."""
    print("ğŸ§ª Starting Comprehensive Pipeline Test")
    print("=" * 50)
    
    # Import after mocking
    from loaders import load_pdf_text, assign_doc_id
    from chunking import simple_chunk
    from tools_scipy import comprehensive_analysis
    from nodes import node_ingest, node_split_embed, node_retrieve, node_analyze, node_scipy_compute, node_decide, node_report
    from schema import GraphState
    from reporter import generate_comprehensive_report, save_complete_analysis
    
    # Test 1: PDF Loading
    print("\nğŸ“„ Test 1: PDF Loading")
    pdf_path = "./data/examples/sample_research.pdf"
    
    if not Path(pdf_path).exists():
        print(f"âŒ Sample PDF not found: {pdf_path}")
        return False
    
    try:
        doc_id = assign_doc_id(pdf_path)
        text = load_pdf_text(pdf_path)
        print(f"âœ… PDF loaded: {doc_id} ({len(text)} characters)")
    except Exception as e:
        print(f"âŒ PDF loading failed: {e}")
        return False
    
    # Test 2: Text Chunking
    print("\nğŸ”ª Test 2: Text Chunking")
    try:
        chunks = simple_chunk(text, doc_id)
        print(f"âœ… Text chunked: {len(chunks)} chunks created")
    except Exception as e:
        print(f"âŒ Text chunking failed: {e}")
        return False
    
    # Test 3: Statistical Analysis
    print("\nğŸ“Š Test 3: Statistical Analysis")
    try:
        scipy_results = comprehensive_analysis(text)
        print(f"âœ… SciPy analysis: {scipy_results['needs_scipy']}")
        print(f"   Analyses performed: {scipy_results.get('analysis_performed', [])}")
    except Exception as e:
        print(f"âŒ Statistical analysis failed: {e}")
        return False
    
    # Test 4: Node Pipeline (with mocks)
    print("\nğŸ”„ Test 4: Node Pipeline")
    try:
        # Initialize state
        state = GraphState()
        state["doc_path"] = pdf_path
        
        # Test ingest node
        state = node_ingest(state)
        if state.get("error"):
            print(f"âŒ Ingest failed: {state['error']}")
            return False
        print(f"âœ… Ingest: {state['doc_id']}")
        
        # Test split_embed node
        state = node_split_embed(state)
        if state.get("error"):
            print(f"âŒ Split/embed failed: {state['error']}")
            return False
        print(f"âœ… Split/embed: {len(state['chunks'])} chunks")
        
        # Test retrieve node
        state = node_retrieve(state)
        if state.get("error"):
            print(f"âŒ Retrieve failed: {state['error']}")
            return False
        print(f"âœ… Retrieve: {len(state['retrieved'])} chunks")
        
        # Test analyze node
        state = node_analyze(state)
        if state.get("error"):
            print(f"âŒ Analyze failed: {state['error']}")
            return False
        print(f"âœ… Analyze: {len(state['analysis'].findings)} findings")
        
        # Test scipy node
        state = node_scipy_compute(state)
        if state.get("error"):
            print(f"âŒ SciPy failed: {state['error']}")
            return False
        print(f"âœ… SciPy: {len(state['scipy_out'].get('analysis_performed', []))} analyses")
        
        # Test decide node
        state = node_decide(state)
        if state.get("error"):
            print(f"âŒ Decide failed: {state['error']}")
            return False
        print(f"âœ… Decide: {state['decision'].label} ({state['decision'].confidence})")
        
        # Test report node
        state = node_report(state)
        if state.get("error"):
            print(f"âŒ Report failed: {state['error']}")
            return False
        print(f"âœ… Report: {len(state['report'].summary)} characters")
        
    except Exception as e:
        print(f"âŒ Node pipeline failed: {e}")
        return False
    
    # Test 5: Report Generation
    print("\nğŸ“ Test 5: Report Generation")
    try:
        comprehensive_report = generate_comprehensive_report(state, include_debug=True)
        print(f"âœ… Comprehensive report: {len(comprehensive_report)} sections")
        
        # Save reports
        report_paths = save_complete_analysis(state, "./storage/reports")
        print(f"âœ… Reports saved: {list(report_paths.keys())}")
        
    except Exception as e:
        print(f"âŒ Report generation failed: {e}")
        return False
    
    # Test 6: CLI Components
    print("\nğŸ’» Test 6: CLI Components")
    try:
        from run_cli import setup_environment
        from graph import get_graph_visualization
        
        # Test environment setup (without API key validation)
        print("âœ… CLI imports successful")
        
        # Test graph visualization
        viz = get_graph_visualization()
        print(f"âœ… Graph visualization: {len(viz)} characters")
        
    except Exception as e:
        print(f"âŒ CLI components failed: {e}")
        return False
    
    print("\nğŸ‰ All Tests Passed!")
    print("=" * 50)
    print("ğŸ“Š Test Summary:")
    print("  âœ… PDF Loading: Working")
    print("  âœ… Text Chunking: Working") 
    print("  âœ… Statistical Analysis: Working")
    print("  âœ… Node Pipeline: Working")
    print("  âœ… Report Generation: Working")
    print("  âœ… CLI Components: Working")
    print("\nğŸš€ Research Agent is fully functional!")
    
    return True

def test_sample_document_analysis():
    """Test with the actual sample document content."""
    print("\nğŸ“‹ Sample Document Analysis Test")
    print("-" * 40)
    
    pdf_path = "./data/examples/sample_research.pdf"
    
    try:
        from loaders import load_pdf_text
        from tools_scipy import comprehensive_analysis
        
        # Load and analyze the sample document
        text = load_pdf_text(pdf_path)
        results = comprehensive_analysis(text)
        
        print(f"ğŸ“„ Document length: {len(text)} characters")
        print(f"ğŸ”¢ Numbers extracted: {results['numbers_extracted']}")
        print(f"ğŸ“Š SciPy analysis needed: {results['needs_scipy']}")
        print(f"ğŸ§® Analyses performed: {results.get('analysis_performed', [])}")
        
        # Show some statistical results
        if 't_test' in results:
            t_result = results['t_test']
            print(f"ğŸ“ˆ T-test p-value: {t_result.get('p_value', 'N/A')}")
            print(f"ğŸ“ˆ T-test significant: {t_result.get('significant', 'N/A')}")
        
        if 'correlation' in results:
            corr_result = results['correlation']
            pearson = corr_result.get('pearson', {})
            print(f"ğŸ”— Correlation: {pearson.get('correlation', 'N/A')}")
            print(f"ğŸ”— Correlation p-value: {pearson.get('p_value', 'N/A')}")
        
        print("âœ… Sample document analysis completed")
        
    except Exception as e:
        print(f"âŒ Sample document analysis failed: {e}")

if __name__ == "__main__":
    print("ğŸ”¬ Research Agent - Complete System Test")
    print("ğŸ¯ Testing all components without external API dependencies")
    print()
    
    # Run comprehensive tests
    success = test_complete_pipeline()
    
    if success:
        # Run sample document analysis
        test_sample_document_analysis()
        
        print(f"\nâœ… System Test Summary: ALL TESTS PASSED")
        print("ğŸ¯ The Research Agent is ready for production use!")
        print("\nğŸ“š To use with real OpenAI API:")
        print("  1. Add your OPENAI_API_KEY to .env file")
        print("  2. Run: python src/run_cli.py run data/examples/sample_research.pdf")
        print("  3. Or start API: python src/api.py")
    else:
        print("\nâŒ System Test Summary: SOME TESTS FAILED")
        sys.exit(1)