import streamlit as st
import os
import json
import tempfile
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

# Ensure environment variables are loaded early
load_dotenv()
import config  # triggers validate_config logic if needed
try:
    config.validate_config()
except Exception:
    pass

# Import our existing modules
from streamlit_analyzer import analyze_text_directly
from embeddings import search_similar, get_collection_info
from loaders import load_pdf_text, validate_pdf_file, assign_doc_id
from nodes import llm
from export_utils import (
    export_to_docx, export_to_pdf_report, export_to_excel, 
    export_chat_to_text, get_available_export_formats
)
from session_manager import (
    save_session, load_session, list_saved_sessions, 
    auto_save_session, load_auto_save, export_session_summary
)
from analytics_utils import (
    generate_analytics_dashboard, create_conversation_timeline, 
    create_question_types_chart, export_analytics_report
)
from langchain_core.prompts import ChatPromptTemplate
import structlog

# Configure logging
structlog.configure(
    processors=[structlog.dev.ConsoleRenderer()],
    wrapper_class=structlog.make_filtering_bound_logger(30),  # WARNING level for cleaner UI
    logger_factory=structlog.WriteLoggerFactory(),
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Page configuration
st.set_page_config(
    page_title="Research Agent - Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø§Ø­Ø«",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for RTL and better styling
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
        background: linear-gradient(90deg, #1e3a8a, #3b82f6);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background-color: #f3e5f5;
        border-left: 4px solid #9c27b0;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    .rtl {
        direction: rtl;
        text-align: right;
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables."""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'current_doc' not in st.session_state:
        st.session_state.current_doc = None
    if 'doc_analysis' not in st.session_state:
        st.session_state.doc_analysis = None
    if 'processed_docs' not in st.session_state:
        st.session_state.processed_docs = []
    if 'auto_save_enabled' not in st.session_state:
        st.session_state.auto_save_enabled = True
    if 'session_start_time' not in st.session_state:
        st.session_state.session_start_time = datetime.now()
    if 'analytics_data' not in st.session_state:
        st.session_state.analytics_data = {
            'questions_asked': 0,
            'exports_created': 0,
            'documents_processed': 0,
            'session_duration': 0
        }

def load_document(uploaded_file):
    """Load and process uploaded PDF."""
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        # Validate PDF
        if not validate_pdf_file(tmp_path):
            st.error("âŒ Ø§Ù„Ù…Ù„Ù Ù„ÙŠØ³ PDF ØµØ§Ù„Ø­")
            return None
        
        # Load text
        doc_id = assign_doc_id(tmp_path)
        text = load_pdf_text(tmp_path)
        
        # Clean up temp file
        os.unlink(tmp_path)
        
        return {
            'doc_id': doc_id,
            'filename': uploaded_file.name,
            'text': text,
            'upload_time': datetime.now(),
            'size': len(text)
        }
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return None

def analyze_document(doc_info):
    """Analyze document using our simplified pipeline."""
    try:
        with st.spinner("ğŸ”¬ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯..."):
            # Use direct text analysis
            result = analyze_text_directly(doc_info['text'], doc_info['doc_id'])
            return result
            
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
        return None

def chat_with_document(user_query, doc_info):
    """Chat with the document using RAG."""
    try:
        # Get LLM instance
        llm_model = llm()
        
        # Search for relevant chunks
        persist_dir = os.getenv("CHROMA_DIR", "./storage/vectors")
        try:
            docs = search_similar(user_query, persist_dir, k=3)
            context = "\n\n".join([doc.page_content for doc in docs])
        except:
            # Fallback to using full text (truncated)
            context = doc_info['text'][:3000]
        
        # Create prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù„Ù„Ø¨Ø§Ø­Ø«ÙŠÙ†. ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…Ø±ÙÙˆØ¹.
- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø§Ù‹
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
- Ø§Ù‚ØªØ¨Ø³ Ù…Ù† Ø§Ù„Ù†Øµ Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†"""),
            ("user", f"""Ø§Ù„Ø³Ø¤Ø§Ù„: {user_query}

Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:
{context}

Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ± Ø£Ø¹Ù„Ø§Ù‡.""")
        ])
        
        # Get response
        messages = prompt.format_messages()
        response = llm_model.invoke(messages)
        
        # Update analytics
        if 'analytics_data' in st.session_state:
            st.session_state.analytics_data['questions_asked'] += 1
        
        # Handle different response types
        if hasattr(response, 'content'):
            return response.content
        elif isinstance(response, str):
            return response
        else:
            return str(response)
        
    except Exception as e:
        return f"âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ: {str(e)}"

def display_document_stats(doc_info, analysis_result=None):
    """Display document statistics."""
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ“„ Ø­Ø¬Ù… Ø§Ù„Ù†Øµ", f"{len(doc_info['text']):,} Ø­Ø±Ù")
    
    with col2:
        word_count = len(doc_info['text'].split())
        st.metric("ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", f"{word_count:,}")
    
    with col3:
        if analysis_result and analysis_result.get('chunks'):
            chunks_count = len(analysis_result['chunks'])
            st.metric("ğŸ§© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡", chunks_count)
        else:
            st.metric("ğŸ§© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡", "ØºÙŠØ± Ù…Ø­Ø³ÙˆØ¨")
    
    with col4:
        if analysis_result and analysis_result.get('decision'):
            confidence = analysis_result['decision'].confidence
            st.metric("ğŸ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", f"{confidence:.0%}")
        else:
            st.metric("ğŸ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", "ØºÙŠØ± Ù…Ø­Ø³ÙˆØ¨")

def display_analysis_results(analysis_result):
    """Display analysis results visually."""
    if not analysis_result:
        return
    
    st.subheader("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    
    # Analysis findings
    if analysis_result.get('analysis') and analysis_result['analysis'].findings:
        st.subheader("ğŸ” Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
        for i, finding in enumerate(analysis_result['analysis'].findings, 1):
            st.write(f"**{i}.** {finding}")
    
    # Decision
    if analysis_result.get('decision'):
        decision = analysis_result['decision']
        
        col1, col2 = st.columns(2)
        with col1:
            # Decision gauge
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = decision.confidence * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"},
                delta = {'reference': 50},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 100], 'color': "gray"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ¯ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
            
            # Color code based on decision
            if decision.label == "relevant":
                st.success(f"âœ… **Ø°Ùˆ ØµÙ„Ø©** (Ø«Ù‚Ø©: {decision.confidence:.0%})")
            elif decision.label == "irrelevant":
                st.error(f"âŒ **ØºÙŠØ± Ø°Ùˆ ØµÙ„Ø©** (Ø«Ù‚Ø©: {decision.confidence:.0%})")
            else:
                st.warning(f"âš ï¸ **ØºÙŠØ± Ù…Ø­Ø¯Ø¯** (Ø«Ù‚Ø©: {decision.confidence:.0%})")
            
            if decision.criteria:
                st.write("**Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:**")
                for criterion in decision.criteria:
                    st.write(f"â€¢ {criterion}")
    
    # SciPy results
    if analysis_result.get('scipy_out') and analysis_result['scipy_out'].get('analysis_performed'):
        st.subheader("ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ")
        
        scipy_results = analysis_result['scipy_out']
        
        # Create tabs for different analyses
        if scipy_results.get('t_test'):
            with st.expander("ğŸ“Š Ø§Ø®ØªØ¨Ø§Ø± T-Test"):
                t_test = scipy_results['t_test']
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("T-Statistic", f"{t_test.get('t_statistic', 0):.3f}")
                    st.metric("P-Value", f"{t_test.get('p_value', 0):.3f}")
                with col2:
                    significant = t_test.get('significant', False)
                    if significant:
                        st.success("Ù†ØªÙŠØ¬Ø© Ø°Ø§Øª Ø¯Ù„Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ©")
                    else:
                        st.info("Ù†ØªÙŠØ¬Ø© ØºÙŠØ± Ø°Ø§Øª Ø¯Ù„Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ©")
        
        if scipy_results.get('correlation'):
            with st.expander("ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·"):
                corr = scipy_results['correlation']
                if corr.get('pearson'):
                    pearson = corr['pearson']
                    st.write(f"**Ù…Ø¹Ø§Ù…Ù„ Ø¨ÙŠØ±Ø³ÙˆÙ†:** {pearson.get('correlation', 0):.3f}")
                    st.write(f"**P-Value:** {pearson.get('p_value', 0):.3f}")

def main():
    """Main Streamlit application."""
    initialize_session_state()
    
    # Check API configuration at startup
    openrouter_key = os.getenv("OPENROUTER_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if (openrouter_key and openrouter_key.startswith("sk-or-v1")) or (openai_key and openai_key.startswith("sk-")):
        st.sidebar.success("âœ… OpenRouter/OpenAI API Ù…ØªØµÙ„")
    else:
        st.sidebar.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…ÙØªØ§Ø­ API ØµØ§Ù„Ø­ - ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¬Ø§Ø¨Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ”¬ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø§Ø­Ø« - Research Agent</h1>
        <p>ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«ÙŠØ©</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar for file upload and settings
    with st.sidebar:
        st.header("ğŸ“ Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª")
        
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± Ù…Ù„Ù PDF",
            type=['pdf'],
            help="Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ù„Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù…Ù†Ø§Ù‚Ø´Ø©"
        )
        
        if uploaded_file is not None:
            if st.button("ğŸ”„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯", type="primary"):
                doc_info = load_document(uploaded_file)
                if doc_info:
                    st.session_state.current_doc = doc_info
                    # Update analytics
                    if 'analytics_data' in st.session_state:
                        st.session_state.analytics_data['documents_processed'] += 1
                    # Start analysis
                    analysis = analyze_document(doc_info)
                    st.session_state.doc_analysis = analysis
                    st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ù†Ø¬Ø§Ø­!")
                    st.rerun()
        
        # Document history
        if st.session_state.processed_docs:
            st.header("ğŸ“š Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
            for doc in st.session_state.processed_docs[-5:]:  # Show last 5
                if st.button(f"ğŸ“„ {doc['filename'][:20]}...", key=f"doc_{doc['doc_id']}"):
                    st.session_state.current_doc = doc
                    st.rerun()
        
        # Settings
        st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # Language preference
        language = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"], index=0)
        
        # Analysis depth
        analysis_depth = st.selectbox(
            "Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
            ["Ø³Ø±ÙŠØ¹", "Ù…ØªÙˆØ³Ø·", "Ø´Ø§Ù…Ù„"],
            index=1
        )
    
    # Main content area
    if st.session_state.current_doc is None:
        # Welcome screen
        st.markdown("### ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø§Ø­Ø«!")
        st.markdown("Ø£Ø¯Ø§Ø© Ø°ÙƒÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙ…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«ÙŠØ© Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙØ§Ø¹Ù„ÙŠØ©")
        
        st.markdown("#### ğŸ¯ ÙƒÙŠÙ ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ØŸ")
        st.markdown("""
        1. ğŸ“ Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
        2. ğŸ” Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„  
        3. ğŸ’¬ Ø§Ø¨Ø¯Ø£ ÙÙŠ Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„ØªÙƒ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        4. ğŸ“Š Ø§Ø³ØªÙƒØ´Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        5. ğŸ“„ ØµØ¯Ù‘Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        """)
        
        st.info("âœ¨ **Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:** Ù…Ù†Ø§Ù‚Ø´Ø© ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØŒ Ø¨Ø­Ø« Ø°ÙƒÙŠØŒ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©ØŒ ØªÙ‚Ø§Ø±ÙŠØ± Ø´Ø§Ù…Ù„Ø©")
        
    else:
        # Document is loaded
        doc = st.session_state.current_doc
        analysis = st.session_state.doc_analysis
        
        # Document info header
        st.success(f"ğŸ“„ **Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…Ø­Ù…Ù„:** {doc['filename']}")
        
        # Display stats
        display_document_stats(doc, analysis)
        
        # Create tabs for different views
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ’¬ Ø§Ù„Ù…Ù†Ø§Ù‚Ø´Ø©", "ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„", "ğŸ” Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù", "ğŸ“„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±", "ğŸ’¾ Ø§Ù„Ø¬Ù„Ø³Ø§Øª", "ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"])
        
        with tab1:
            st.header("ğŸ’¬ Ù†Ø§Ù‚Ø´ Ø§Ù„Ù…Ø³ØªÙ†Ø¯")
            
            # Add quick question suggestions
            st.subheader("ğŸ’¡ Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚ØªØ±Ø­Ø©")
            suggested_questions = [
                "Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¶ÙˆØ¹ Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø­Ø«ØŸ",
                "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŸ", 
                "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©ØŸ",
                "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ù‡Ù…Ø©ØŸ",
                "Ù…Ø§ Ù‡ÙŠ Ø§Ù„ØªÙˆØµÙŠØ§ØªØŸ",
                "Ù…Ù† Ù‡Ù… Ø§Ù„Ù…Ø¤Ù„ÙÙˆÙ†ØŸ"
            ]
            
            cols = st.columns(3)
            for i, question in enumerate(suggested_questions):
                with cols[i % 3]:
                    if st.button(question, key=f"suggested_{i}", help="Ø§Ø¶ØºØ· Ù„Ø·Ø±Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„"):
                        # Add to chat history
                        st.session_state.chat_history.append({
                            'role': 'user',
                            'content': question
                        })
                        
                        # Get AI response
                        with st.spinner("ğŸ¤” Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙŠÙÙƒØ±..."):
                            response = chat_with_document(question, doc)
                        
                        # Add assistant response
                        st.session_state.chat_history.append({
                            'role': 'assistant',
                            'content': response
                        })
                        
                        st.rerun()
            
            st.divider()
            
            # Chat interface with better styling
            st.subheader("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙØ§Ø¹Ù„ÙŠØ©")
            
            # Display chat history in a container
            chat_container = st.container()
            
            with chat_container:
                if not st.session_state.chat_history:
                    st.info("ğŸ‘‹ Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙŠÙ…ÙƒÙ†Ùƒ Ø·Ø±Ø­ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ø£Ø¹Ù„Ø§Ù‡.")
                
                # Display chat messages
                for i, message in enumerate(st.session_state.chat_history):
                    if message['role'] == 'user':
                        with st.chat_message("user", avatar="ğŸ‘¤"):
                            st.write(message['content'])
                    else:
                        with st.chat_message("assistant", avatar="ğŸ¤–"):
                            st.write(message['content'])
            
            # Chat input at the bottom
            user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... (Ø§Ø¶ØºØ· Enter Ù„Ù„Ø¥Ø±Ø³Ø§Ù„)")
            
            if user_input:
                # Add user message
                st.session_state.chat_history.append({
                    'role': 'user',
                    'content': user_input
                })
                
                # Get AI response
                with st.spinner("ğŸ¤” Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙŠÙÙƒØ±..."):
                    response = chat_with_document(user_input, doc)
                
                # Add assistant response
                st.session_state.chat_history.append({
                    'role': 'assistant',
                    'content': response
                })
                
                st.rerun()
            
            # Chat controls
            st.divider()
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", help="Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„"):
                    st.session_state.chat_history = []
                    st.rerun()
            
            with col2:
                if st.button("ğŸ“‹ Ù†Ø³Ø® Ø¢Ø®Ø± Ø¥Ø¬Ø§Ø¨Ø©", help="Ù†Ø³Ø® Ø¢Ø®Ø± Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯"):
                    if st.session_state.chat_history:
                        last_assistant = None
                        for msg in reversed(st.session_state.chat_history):
                            if msg['role'] == 'assistant':
                                last_assistant = msg['content']
                                break
                        if last_assistant:
                            st.code(last_assistant, language=None)
                        else:
                            st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù„Ù„Ù†Ø³Ø®")
                    else:
                        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø©")
            
            with col3:
                chat_count = len(st.session_state.chat_history)
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", chat_count)
        
        with tab2:
            st.header("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯")
            display_analysis_results(analysis)
        
        with tab3:
            st.header("ğŸ” Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
            
            # Search functionality
            search_query = st.text_input("ğŸ” Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:")
            
            if search_query:
                with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
                    try:
                        persist_dir = os.getenv("CHROMA_DIR", "./storage/vectors")
                        docs = search_similar(search_query, persist_dir, k=5)
                        
                        st.subheader(f"ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: '{search_query}'")
                        
                        for i, doc_result in enumerate(docs, 1):
                            with st.expander(f"Ù†ØªÙŠØ¬Ø© {i}"):
                                st.write(doc_result.page_content)
                                if hasattr(doc_result, 'metadata'):
                                    st.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {doc_result.metadata}")
                    except Exception as e:
                        st.warning("âš ï¸ Ø§Ù„Ø¨Ø­Ø« ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹")
            
            # Word cloud or frequency analysis could go here
            st.subheader("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Øµ")
            
            if doc['text']:
                words = doc['text'].split()
                word_count = len(words)
                unique_words = len(set(words))
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", f"{word_count:,}")
                with col2:
                    st.metric("Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©", f"{unique_words:,}")
        
        with tab4:
            st.header("ğŸ“„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± ÙˆØ§Ù„ØªØµØ¯ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
            
            st.subheader("ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±")
            
            # Show available formats
            formats = get_available_export_formats()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ğŸ“„ ØªÙ‚Ø§Ø±ÙŠØ± Ø´Ø§Ù…Ù„Ø©")
                
                # DOCX Export
                if st.button("ï¿½ ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ Word (DOCX)", type="primary", key="docx_export"):
                    with st.spinner("ğŸ“ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Word..."):
                        filepath = export_to_docx(doc, analysis, st.session_state.chat_history)
                        if filepath.startswith("Ø®Ø·Ø£"):
                            st.error(filepath)
                        else:
                            with open(filepath, "rb") as file:
                                st.download_button(
                                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Word",
                                    data=file.read(),
                                    file_name=os.path.basename(filepath),
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                            st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Word: {os.path.basename(filepath)}")
                
                # PDF Export
                if st.button("ğŸ“„ ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ PDF", type="secondary", key="pdf_export"):
                    with st.spinner("ğŸ“„ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù PDF..."):
                        filepath = export_to_pdf_report(doc, analysis, st.session_state.chat_history)
                        if filepath.startswith("Ø®Ø·Ø£"):
                            st.error(filepath)
                        else:
                            with open(filepath, "rb") as file:
                                st.download_button(
                                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDF",
                                    data=file.read(),
                                    file_name=os.path.basename(filepath),
                                    mime="application/pdf"
                                )
                            st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù PDF: {os.path.basename(filepath)}")
                
                # Excel Export
                if st.button("ğŸ“Š ØªØµØ¯ÙŠØ± Ø¥Ù„Ù‰ Excel", key="excel_export"):
                    with st.spinner("ğŸ“Š Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel..."):
                        filepath = export_to_excel(doc, analysis, st.session_state.chat_history)
                        if filepath.startswith("Ø®Ø·Ø£"):
                            st.error(filepath)
                        else:
                            with open(filepath, "rb") as file:
                                st.download_button(
                                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Excel",
                                    data=file.read(),
                                    file_name=os.path.basename(filepath),
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            st.success(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel: {os.path.basename(filepath)}")
            
            with col2:
                st.markdown("### ğŸ’¬ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª")
                
                # Chat history export
                if st.button("ğŸ’¬ ØªØµØ¯ÙŠØ± Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", key="chat_export"):
                    if st.session_state.chat_history:
                        with st.spinner("ğŸ’¬ Ø¬Ø§Ø±ÙŠ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©..."):
                            filepath = export_chat_to_text(st.session_state.chat_history, doc)
                            if filepath.startswith("Ø®Ø·Ø£"):
                                st.error(filepath)
                            else:
                                with open(filepath, "r", encoding="utf-8") as file:
                                    st.download_button(
                                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
                                        data=file.read(),
                                        file_name=os.path.basename(filepath),
                                        mime="text/plain"
                                    )
                                st.success(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©: {os.path.basename(filepath)}")
                    else:
                        st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ù„ØªØµØ¯ÙŠØ±")
                
                # JSON Export (Enhanced)
                if st.button("ï¿½ ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù… (JSON)", key="json_export"):
                    export_data = {
                        'metadata': {
                            'export_time': datetime.now().isoformat(),
                            'version': '2.0',
                            'type': 'research_agent_export'
                        },
                        'document': {
                            'filename': doc['filename'],
                            'doc_id': doc['doc_id'],
                            'text_length': len(doc['text']),
                            'word_count': len(doc['text'].split()),
                            'upload_time': doc['upload_time'].isoformat() if hasattr(doc['upload_time'], 'isoformat') else str(doc['upload_time'])
                        },
                        'analysis': {
                            'success': analysis.get('success', False) if analysis else False,
                            'findings': analysis.get('analysis', {}).findings if analysis and analysis.get('analysis') else [],
                            'decision': {
                                'label': analysis.get('decision', {}).label if analysis and analysis.get('decision') else 'unknown',
                                'confidence': analysis.get('decision', {}).confidence if analysis and analysis.get('decision') else 0,
                                'criteria': analysis.get('decision', {}).criteria if analysis and analysis.get('decision') else []
                            } if analysis and analysis.get('decision') else None,
                            'scipy_results': analysis.get('scipy_out', {}) if analysis else {}
                        },
                        'chat_history': st.session_state.chat_history,
                        'statistics': {
                            'total_messages': len(st.session_state.chat_history),
                            'user_messages': len([m for m in st.session_state.chat_history if m['role'] == 'user']),
                            'assistant_messages': len([m for m in st.session_state.chat_history if m['role'] == 'assistant'])
                        }
                    }
                    
                    st.download_button(
                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (JSON)",
                        data=json.dumps(export_data, ensure_ascii=False, indent=2, default=str),
                        file_name=f"data_{doc['doc_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
            
            # Export status and info
            st.subheader("ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±")
            
            with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ ØµÙŠØº Ø§Ù„ØªØµØ¯ÙŠØ±"):
                for format_name, extension, status in formats:
                    if "Ù…ØªØ§Ø­" in status and "ØºÙŠØ±" not in status:
                        st.success(f"âœ… **{format_name}** (.{extension}) - {status}")
                    else:
                        st.warning(f"âš ï¸ **{format_name}** (.{extension}) - {status}")
                
                st.info("""
                **Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‡Ø§Ù…Ø©:**
                - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØµØ¯Ø±Ø© ØªÙØ­ÙØ¸ Ù…Ø¹ Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ
                - ÙŠÙ…ÙƒÙ† ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pip
                - Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØµØ¯Ø±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
                """)
            
            # Quick stats
            if analysis:
                st.subheader("ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    findings_count = len(analysis.get('analysis', {}).findings) if analysis.get('analysis') else 0
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", findings_count)
                
                with col2:
                    chat_count = len(st.session_state.chat_history)
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", chat_count)
                
                with col3:
                    confidence = analysis.get('decision', {}).confidence if analysis.get('decision') else 0
                    st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", f"{confidence:.0%}")
                
                with col4:
                    scipy_analyses = len(analysis.get('scipy_out', {}).get('analysis_performed', [])) if analysis.get('scipy_out') else 0
                    st.metric("Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©", scipy_analyses)

        # Sessions Management Tab
        with tab5:
            st.header("ğŸ’¾ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.subheader("ğŸ”„ Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©")
                
                # Auto-save settings
                auto_save_enabled = st.checkbox(
                    "ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ", 
                    value=st.session_state.get('auto_save_enabled', True),
                    help="Ø³ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚"
                )
                st.session_state.auto_save_enabled = auto_save_enabled
                
                # Manual save
                if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©", type="primary"):
                    session_data = {
                        'current_doc': st.session_state.current_doc,
                        'doc_analysis': st.session_state.doc_analysis,
                        'chat_history': st.session_state.chat_history,
                        'processed_docs': st.session_state.processed_docs,
                        'analytics_data': st.session_state.analytics_data
                    }
                    
                    saved_path = save_session(session_data)
                    if saved_path and not saved_path.startswith("Ø®Ø·Ø£"):
                        st.success(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­: {Path(saved_path).name}")
                        st.session_state.analytics_data['exports_created'] += 1
                    else:
                        st.error(saved_path)
                
                # Session export
                if st.button("ğŸ“‹ ØªØµØ¯ÙŠØ± Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ù„Ø³Ø©"):
                    session_data = {
                        'current_doc': st.session_state.current_doc,
                        'chat_history': st.session_state.chat_history,
                        'analytics_data': st.session_state.analytics_data
                    }
                    
                    summary = export_session_summary(session_data)
                    
                    st.download_button(
                        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ø®Øµ Ø§Ù„Ø¬Ù„Ø³Ø©",
                        data=summary,
                        file_name=f"session_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
            
            with col2:
                st.subheader("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©")
                
                # Calculate session duration
                session_duration = datetime.now() - st.session_state.session_start_time
                duration_minutes = int(session_duration.total_seconds() / 60)
                
                # Update analytics
                st.session_state.analytics_data['session_duration'] = duration_minutes
                
                # Display metrics
                st.metric("Ù…Ø¯Ø© Ø§Ù„Ø¬Ù„Ø³Ø©", f"{duration_minutes} Ø¯Ù‚ÙŠÙ‚Ø©")
                st.metric("Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø·Ø±ÙˆØ­Ø©", st.session_state.analytics_data['questions_asked'])
                st.metric("Ø§Ù„ØªØµØ¯ÙŠØ±Ø§Øª Ø§Ù„Ù…Ù†Ø´Ø£Ø©", st.session_state.analytics_data['exports_created'])
                st.metric("Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", st.session_state.analytics_data['documents_processed'])
                
                # Session health
                if duration_minutes > 30:
                    st.info("ğŸ’¡ Ø¬Ù„Ø³Ø© Ø·ÙˆÙŠÙ„Ø© - ÙÙƒØ± ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù…")
                
                if len(st.session_state.chat_history) > 20:
                    st.info("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ÙƒØ«ÙØ© - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            
            st.markdown("---")
            
            # Saved sessions list
            st.subheader("ğŸ“‚ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
            
            saved_sessions = list_saved_sessions()
            
            if saved_sessions:
                for session in saved_sessions[:10]:  # Show last 10 sessions
                    with st.expander(f"ğŸ“„ {session['doc_filename']} - {session['timestamp'][:16]}"):
                        col1, col2, col3 = st.columns([2, 1, 1])
                        
                        with col1:
                            st.write(f"**Ø§Ù„Ù…Ø³ØªÙ†Ø¯:** {session['doc_filename']}")
                            st.write(f"**Ø§Ù„Ù…Ø¹Ø±Ù:** {session['doc_id']}")
                            st.write(f"**Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„:** {session['chat_count']}")
                            st.write(f"**Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù:** {session['file_size']:,} Ø¨Ø§ÙŠØª")
                        
                        with col2:
                            if st.button(f"ğŸ“‚ Ø§Ø³ØªØ¹Ø§Ø¯Ø©", key=f"load_{session['filename']}"):
                                loaded_session = load_session(session['filepath'])
                                if loaded_session:
                                    st.session_state.current_doc = loaded_session.get('current_doc')
                                    st.session_state.doc_analysis = loaded_session.get('doc_analysis')
                                    st.session_state.chat_history = loaded_session.get('chat_history', [])
                                    st.session_state.processed_docs = loaded_session.get('processed_docs', [])
                                    st.success("âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                                    st.rerun()
                                else:
                                    st.error("âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¬Ù„Ø³Ø©")
                        
                        with col3:
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„",
                                data=open(session['filepath'], 'r', encoding='utf-8').read(),
                                file_name=session['filename'],
                                mime="application/json",
                                key=f"download_{session['filename']}"
                            )
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ù„Ø³Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†")
            
            # Auto-save status
            if auto_save_enabled and st.session_state.current_doc:
                # Try auto-save
                session_data = {
                    'current_doc': st.session_state.current_doc,
                    'chat_history': st.session_state.chat_history,
                    'doc_analysis': st.session_state.doc_analysis
                }
                
                if auto_save_session(session_data):
                    st.success("ğŸ’¾ ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ", icon="âœ…")
        
        # Advanced Analytics Tab
        with tab6:
            st.header("ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
            
            if not st.session_state.current_doc:
                st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ø³ØªÙ†Ø¯ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
            else:
                # Generate analytics data
                session_data = {
                    'chat_history': st.session_state.chat_history,
                    'current_doc': st.session_state.current_doc,
                    'analytics_data': st.session_state.analytics_data
                }
                
                analytics = generate_analytics_dashboard(session_data, st.session_state.doc_analysis)
                
                # Main analytics overview
                st.subheader("ğŸ“Š Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
                
                if analytics.get('session_overview'):
                    overview = analytics['session_overview']
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", overview.get('total_messages', 0))
                    with col2:
                        st.metric("â“ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", overview.get('user_questions', 0))
                    with col3:
                        st.metric("ğŸ’­ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…", overview.get('assistant_responses', 0))
                    with col4:
                        st.metric("ğŸ“– Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", f"{overview.get('word_count', 0):,}")
                
                # Conversation analysis
                if analytics.get('chat_analysis') and st.session_state.chat_history:
                    st.subheader("ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
                    
                    chat_analysis = analytics['chat_analysis']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", f"{chat_analysis.get('avg_user_message_length', 0):.0f} Ø­Ø±Ù")
                        st.metric("Ø£Ø·ÙˆÙ„ Ø³Ø¤Ø§Ù„", f"{chat_analysis.get('longest_user_message', 0)} Ø­Ø±Ù")
                    
                    with col2:
                        st.metric("Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª", f"{chat_analysis.get('avg_assistant_message_length', 0):.0f} Ø­Ø±Ù")
                        st.metric("Ø£Ø·ÙˆÙ„ Ø¥Ø¬Ø§Ø¨Ø©", f"{chat_analysis.get('longest_assistant_message', 0)} Ø­Ø±Ù")
                    
                    # Conversation timeline
                    timeline_fig = create_conversation_timeline(st.session_state.chat_history)
                    if timeline_fig:
                        st.plotly_chart(timeline_fig, use_container_width=True)
                
                # Question types analysis
                if analytics.get('question_analysis'):
                    st.subheader("â“ ØªØ­Ù„ÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
                    
                    question_chart = create_question_types_chart(analytics['question_analysis'])
                    if question_chart:
                        st.plotly_chart(question_chart, use_container_width=True)
                    else:
                        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ø¦Ù„Ø© ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
                
                # Document analysis insights
                if analytics.get('document_analysis'):
                    st.subheader("ğŸ“„ Ø±Ø¤Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯")
                    
                    doc_analysis = analytics['document_analysis']
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        success = doc_analysis.get('analysis_success', False)
                        st.metric("Ø­Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„", "âœ… Ù†Ø¬Ø­" if success else "âŒ ÙØ´Ù„")
                    
                    with col2:
                        findings = doc_analysis.get('findings_count', 0)
                        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", findings)
                    
                    with col3:
                        confidence = doc_analysis.get('decision_confidence', 0)
                        st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", f"{confidence:.1%}")
                
                # Export analytics
                st.subheader("ğŸ“¤ ØªØµØ¯ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ“Š ØªØµØ¯ÙŠØ± JSON", type="secondary"):
                        export_data = export_analytics_report(analytics, 'json')
                        if export_data:
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ JSON",
                                data=export_data['content'],
                                file_name=export_data['filename'],
                                mime=export_data['mime_type']
                            )
                
                with col2:
                    if st.button("ğŸ“ ØªØµØ¯ÙŠØ± Ù†ØµÙŠ", type="secondary"):
                        export_data = export_analytics_report(analytics, 'text')
                        if export_data:
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ù†Øµ",
                                data=export_data['content'],
                                file_name=export_data['filename'],
                                mime=export_data['mime_type']
                            )
                
                with col3:
                    if st.button("ğŸ“‹ ØªØµØ¯ÙŠØ± CSV", type="secondary"):
                        export_data = export_analytics_report(analytics, 'csv')
                        if export_data:
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ CSV",
                                data=export_data['content'],
                                file_name=export_data['filename'],
                                mime=export_data['mime_type']
                            )
                
                # Session insights
                if st.session_state.analytics_data:
                    st.subheader("ğŸ” Ø±Ø¤Ù‰ Ø§Ù„Ø¬Ù„Ø³Ø©")
                    
                    session_duration = (datetime.now() - st.session_state.session_start_time).total_seconds() / 60
                    
                    insights = []
                    
                    if session_duration > 30:
                        insights.append("â° Ø¬Ù„Ø³Ø© Ø·ÙˆÙŠÙ„Ø© - Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„Ø£Ø®Ø° Ø§Ø³ØªØ±Ø§Ø­Ø©")
                    
                    if len(st.session_state.chat_history) > 15:
                        insights.append("ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ÙƒØ«ÙØ© - ÙŠÙÙ†ØµØ­ Ø¨Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
                    
                    if st.session_state.analytics_data['questions_asked'] > 20:
                        insights.append("â“ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© - ØªÙØ§Ø¹Ù„ Ù…Ù…ØªØ§Ø² Ù…Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
                    
                    if analytics.get('chat_analysis', {}).get('avg_user_message_length', 0) > 200:
                        insights.append("ğŸ“ Ø£Ø³Ø¦Ù„Ø© Ù…ÙØµÙ„Ø© - ØªØ¸Ù‡Ø± ÙÙ‡Ù…Ø§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹")
                    
                    if insights:
                        for insight in insights:
                            st.info(insight)
                    else:
                        st.success("âœ… Ø¬Ù„Ø³Ø© Ù…ØªÙˆØ§Ø²Ù†Ø© ÙˆÙØ¹Ø§Ù„Ø©")

if __name__ == "__main__":
    main()
